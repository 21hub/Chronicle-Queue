= User Guide
Peter Lawrey
:toc: manual
:toc-placement: preamble

Chronicle Queue is a distributed unbounded persisted queue. 
It supports asycnhronous RMI and Publish/Subscribe interfaces with sub-milli-second latencies. 
In optimised examples a message can passed between JVM in under a micro-second.
Chronicle Queue provides stable real latencies into the millions of messages per second.

== How does Chronicle Queue v4 work

=== Terminology

Basic terminology.

- messages are grouped by *topics* A topic can contain any number of *sub-topics* which are logically stores together in that topic.
- an *appender* is the source of messages.
- a *tailer* is a receiver of messages.
- *Chronicle Queue* in brokerless by default. You can use *Chronicle Engine* to act as a broker for remote access.

NOTE: We deliberately avoid the term *consumer* as messages are not consumed/destroyed by reading.

At a high level, *appenders* append to a queue and, *tailers* keep readin from the next available message.

By using Chronicle Engine, you can publish to a *queue* to act as a *remote appender*, and you *subscribe* to a queue to act as a *remote tailer*

=== Topics and Queue files.

Each topic is a directory of queues.  There is a file for each roll cycle. If you have topics call `mytopic` the layout could look like this

[source]
----
mytopic/
    20160710.cq4
    20160711.cq4
    20160712.cq4
    20160713.cq4
----

To copy all the data for a single day (or cycle) you can copy the file for that day on to your development machine for replay testing.

=== File Retention

You can add a notifier when file are rotated as a `StoreFileListener` and this can be used to delete files after a period of time, however files are retained forever by default.  Our biggest users have over 100 TB retained.

The only thing each tailer retains is an index which is composed as a cycle number e.g. days since epoch and a sequence number within that cycle.
In the case of `DAILY` cycle, the sequence number is 32 bit and the `index = ((long) cycle << 32) | sequenceNumber` so printing the index in hexadecimal is common in our libraries.

An appender and tailer is very cheap as they don't even require a TCP connection. They are just a few Java objects.

Rather than partition the queue files across servers, we support each server supporting as much data as you have disk space. 
This is much more scalable than being limited to the amount of memory space you have.
You can buy a redundant pair of 6 TB of enterprise disks for $700 (retail) at the time of writing (July 2016) and that is much cheaper than 6 TB memory.

=== Restrictions on topics and messages.

Topics are limited to being strings which can be used as directory names.  
Within a topic you can have sub-topics which be anything data type which can be serialized.
Messages can be anything which can be serialized.

Chronicle Queue supports;

- `Serializable` objects, though this is to be avoided as it is not efficient
- `Externalizable`
- byte[] and String
- `Marshallable` which is a self describing message which can be written as YAML, Binary YAML or JSON.
- `BytesMarshallable` which is low level binary or text encoding.

=== Tailer see every message.

Every tailer sees every message. An abstraction can be added to filter messages or assign messages to just one message processor, 
however in general you only need one main consumer for a topic and possibly some supporting tailers for monitoring etc.

As Chronicle Queue doesn't partition it's topics, you get total ordering of all messages within that topic.  
Across topics there is no guarentee of ordering and if you want to replay deterministically from a system which consumes from multiple topics we suggest replaying from that systems output.

=== Replaying from the output, not the input.

It is common practice to replay a state machine from it's inputs.  This has two flaws;

- you have either one input, or you can always determine the order the inputs were consumed.
- you have not changed the software (or all the software is stored in the queue)

If you want to be able to upgrade your system you want o replay for the output.

Replaying from the output means;

- you have a record of the order of the inputs you processed.
- you have a record of all the decisions your new system is commited to, even if the new code would have made different decisions.

=== Guarentees

Chronicle Queue provides the following guarentees

- for each appender, messages are written in the order the appnder wrote them. Messages by different appenders are interleaved.
- for each tailer, it will see every message for a topic in the same order as every other tailer.
- when replicated, every replica has a copy of every message.

Replication has three levels of gaurentees

- replication happens soon but eventually (< 1ms in as much as 99.9% of cases)
- or, a tailer will only see messages which have been replicated.
- or, an appender doesn't return until a replica has acknowledged it has been received.

== Use Cases

Chronicle Queue is most often use for "Producer Centric" systems where you need to retain a lot of data for days or years.

=== What is a Producer Centric system?

Most messaging systems are "Consumer Centric", a common example is a user GUI.  
You can have multiple users on different machines, different quality of networks, doing a variety of other things for the user at different times.
In particaulr, a user can only take in som much data. For this reason it makes sense for the client consumer to tell the producer when and when not to give them more data. 
It should detemine how flow control works.

Chronicle Queue is a "Producer Centric" solution and does everything possible to never push back on the producer or tell it to slow down.
As such it is a power tool as a big buffer between your system and an upstream producer you have little or not control over.

=== Market Data

When your receive market data from a publisher you don't have the option to push back on the producer for long if at all. 
A few of our users consume data from CME OPRA. This produces peaks of 10 million events per second and these are sent as UDP packets 
without any retry. If you miss or drop a packet it is lost.  You have to consume and record those packets as fast they come to you
with very little buffering in the network adapter to save you.

For market data in particular real time means around *1 micro-second*, it doesn't mean intra-day.

Chronicle Queue is fast and efficient enough it has been used to increase the speed that data is passed between threads, 
even though it also keep a record of every message passed.

=== Compliance Systems

Complicate Systems are required by more and more systems these days.  Everyone has to have them but no one wants to be slowed down by them.
By using Chronicle Queue to buffer data between monitored system and the compliance system, you don't need to worry about the impact 
of complicate recording for your monitored systems.

Again, Chronicle Queue can support millions of events per second per server and access data which has been retained for years.

=== Messaging

Chronicle Queue support low latency IPC between JVMs on the same machine ~ 1 micro-second, and between machines with a typical latency of 10 micro-seconds for
modest throughputs of a few hundred thousand.  Chronicle Queue support throughputs over a millions of events per second with stable micro-seconds latencies.

=== Metrics

Chronicle Queue can be monitored to obtain latency, through put and activity metrics in real time.

=== Log Replacement

As Chronicle Queue can be used to build state machines, all the information about the state of those components
 can be reproduced externally without direct access to the the components or their state.  This significantly reduces the need for additional logging.
  However any logging you do need can be recorded in great detail.  This makes enabling DEBUG logging in production practical as the cost of logging is very low, in the single digit micro-seconds.
  Logs can be replicated centrally for log consolidation.

Chronicle Queue is being used to store 100+ TB of data which can be replayed from any point in time.

=== Lambda Stream Processing

Streaming components are highly performant, deterministic and have reproducable.
You can reproduce bugs which only show up after a million events played in a particular order, with accelerated realistic timings.

This makes using Stream Processing attractive for systems which need a high degree of quality outcomes.

== Using Chronicle Queue

Chronicle Queue is designed to be driven from code.  You can easily add an interface which suits you needs.

=== Writing to a Queue

Once you start writing to a queue, you have a choice of high level interfaces, to lower level API down to raw memory access.

[source, Java]
----
try (ChronicleQueue queue = SingleChronicleQueueBuilder.binary(path + "/trades").build()) {
   final ExcerptAppender appender = queue.acquireAppender();
----

This the highest level API which hides the fact you are writing to messaging at all. The benefit is; you can swap calls to the interface with a real component or an interface to a different protocol.

[source, Java]
----
// using the method writer interface.
RiskMonitor riskMonitor = appender.methodWriter(RiskMonitor.class);
final LocalDateTime now = LocalDateTime.now(Clock.systemUTC());
riskMonitor.trade(new TradeDetails(now, "GBPUSD", 1.3095, 10e6, Side.Buy, "peter"));
----

You can write a self describing message.  Such messages can support schema changes. They are also easier to understand when debugging or diagnosing problems.

[source, Java]
----
// writing a self describing message
appender.writeDocument(w -> w.write("trade").marshallable(
        m -> m.write("timestamp").dateTime(now)
                .write("symbol").text("EURUSD")
                .write("price").float64(1.1101)
                .write("quantity").float64(15e6)
                .write("side").object(Side.class, Side.Sell)
                .write("trader").text("peter")));
----

You can write raw data which is self describing (the types will always be correct, position is the only indication as to the meaning of those values)

[source, Java]
----
// writing just data
appender.writeDocument(w -> w
        .getValueOut().int32(0x123456)
        .getValueOut().int64(0x999000999000L)
        .getValueOut().text("Hello World"));
----

You can write raw data which is not delf describing. Your reader must know what this data means and the types which were used.

[source, Java]
----
// writing raw data
appender.writeBytes(b -> b
        .writeByte((byte) 0x12)
        .writeInt(0x345678)
        .writeLong(0x999000999000L)
        .writeUtf8("Hello World"));
----

This is the lowest level way to write data.  You get an address to raw memory and you can write what you want.

[source, Java]
----
// Unsafe low level
appender.writeBytes(b -> {
    long address = b.address(b.writePosition());
    Unsafe unsafe = UnsafeMemory.UNSAFE;
    unsafe.putByte(address, (byte) 0x12);
    address += 1;
    unsafe.putInt(address, 0x345678);
    address += 4;
    unsafe.putLong(address, 0x999000999000L);
    address += 8;
    byte[] bytes = "Hello World".getBytes(StandardCharsets.ISO_8859_1);
    unsafe.copyMemory(bytes, Unsafe.ARRAY_BYTE_BASE_OFFSET, null, address, bytes.length);
    b.writeSkip(1 + 4 + 8 + bytes.length);
});
----

You can print the contents of the queue. You can see the first two and last two messages store the same data.

[source, Java]
----
// dump the content of the queue
System.out.println(queue.dump());
----

Prints

[source, Yaml]
----
# position: 262568, header: 0
--- !!data #binary
trade: {
  timestamp: 2016-07-17T15:18:41.141,
  symbol: GBPUSD,
  price: 1.3095,
  quantity: 10000000.0,
  side: Buy,
  trader: peter
}
# position: 262684, header: 1
--- !!data #binary
trade: {
  timestamp: 2016-07-17T15:18:41.141,
  symbol: EURUSD,
  price: 1.1101,
  quantity: 15000000.0,
  side: Sell,
  trader: peter
}
# position: 262800, header: 2
--- !!data #binary
!int 1193046
168843764404224
Hello World
# position: 262830, header: 3
--- !!data #binary
000402b0       12 78 56 34 00 00  90 99 00 90 99 00 00 0B   ·xV4·· ········
000402c0 48 65 6C 6C 6F 20 57 6F  72 6C 64                Hello Wo rld     
# position: 262859, header: 4
--- !!data #binary
000402c0                                               12                 ·
000402d0 78 56 34 00 00 90 99 00  90 99 00 00 0B 48 65 6C xV4····· ·····Hel
000402e0 6C 6F 20 57 6F 72 6C 64                          lo World         
----

=== Reading from a Queue

Reading the queue follows the same pattern except there is a possability there is not message when you attempt to read it.

.Start Reading
[source, Java]
----
try (ChronicleQueue queue = SingleChronicleQueueBuilder.binary(path + "/trades").build()) {
   final ExcerptTailer tailer = queue.createTailer();
----

You can turn each message into a method call based on the content of the message

[source, Java]
----
// reading using method calls
RiskMonitor monitor = System.out::println;
MethodReader reader = tailer.methodReader(monitor);
// read one message
assertTrue(reader.readOne());
----

You can decode the message yourself. Note: the names, type and order of the fields doesn't have to match.

[source, Java]
----
assertTrue(tailer.readDocument(w -> w.read("trade").marshallable(
        m -> {
            LocalDateTime timestamp = m.read("timestamp").dateTime();
            String symbol = m.read("symbol").text();
            double price = m.read("price").float64();
            double quantity = m.read("quantity").float64();
            Side side = m.read("side").object(Side.class);
            String trader = m.read("trader").text();
            // do something with values.
        })));
----

You can read self-describing data values. This will check the types are right and convert as required.

[source, Java]
----
assertTrue(tailer.readDocument(w -> {
    ValueIn in = w.getValueIn();
    int num = in.int32();
    long num2 = in.int64();
    String text = in.text();
    // do something with values
}));
----

You can read raw data as primitives and Strings

[source, Java]
----
assertTrue(tailer.readBytes(in -> {
    int code = in.readByte();
    int num = in.readInt();
    long num2 = in.readLong();
    String text = in.readUtf8();
    assertEquals("Hello World", text);
    // do something with values
}));
----

Or you can get the underlying memory address and access the native memory.

[source, Java]
----
assertTrue(tailer.readBytes(b -> {
    long address = b.address(b.readPosition());
    Unsafe unsafe = UnsafeMemory.UNSAFE;
    int code = unsafe.getByte(address);
    address++;
    int num = unsafe.getInt(address);
    address += 4;
    long num2 = unsafe.getLong(address);
    address += 8;
    int length = unsafe.getByte(address);
    address++;
    byte[] bytes = new byte[length];
    unsafe.copyMemory(null, address, bytes, Unsafe.ARRAY_BYTE_BASE_OFFSET, bytes.length);
    String text = new String(bytes, StandardCharsets.UTF_8);
    assertEquals("Hello World", text);
    // do something with values
}));
----

== Changes from Queue v3

Queue v4 attempts to solve a number of issues with Queue v3.

- without self describing messages, users had to create their own for dumping messages and long term storage of data.  They can still do so, but don't have to.
- Vanilla Chronicle Queue would create a file per thread. This is fine if the number of threads is controlled however many applications have little or not control over how many threads are used and this caused usability problems.
- The configruation for Indexed and Vanilla Chronicle was entirely in code so the reader had to have the same configuration as the writers and it wasn't always clear what that was.
- There was no way for the producer to know how much data had been replicated to the consumer. The only work around was to replicate data back to the producers.
- You needed to specify the size of data to reserve before you started the message.
- You needed to do your own locking for appender in Indexed Chronicle.

=== Can I use Chronicle v3 and v4.

Yes. they use different packages. Queue v4 is a complete re-write so there is no problem using it at the same time as v3.

=== Migrating from Queue v2 and v3.

In Queue v3, everything was in terms of Bytes, not wire.  There is two ways to use byte in Queue v4.  You can use the `writeBytes` and `readBytes` methods, or you can get the `bytes()` from the wire e.g.

.Writing and reading bytes using a lambda
[source, Java]
----
appender.writeBytes(b -> b.writeInt(1234).writeDouble(1.111));

boolean present = tailer.readBytes(b -> process(b.readInt(), b.readDouble()));
----

.Writing to a queue without using a lambda
[source, Java]
----
try (DocumentContext dc = appender.writingDocument()) {
    Bytes bytes = dc.wire().bytes();
    // write to bytes
}

try (DocumentContext dc = tailer.readingDocument()) {
    if (dc.isPresent()) {
        Bytes bytes = dc.wire().bytes();
        // read from bytes
    }
}
----

== Broker configuration

Chronicle Queue doesn't use a broker. If youw ant remote access to a queue either and a producer or subscriber you cna use Chronicle Queue.  Chronicle Engine Enterprise has a C# client as well.

== Design

=== Motivation

Chronicle Queue is designed to be a record everything store which can read in micro-second latency real time.  This supports even the most demeanding High Frequency Trading systems, however it can be used in any application where the recording of information is a concern.

Chronicle Queue Enterprise is design to support reliable replication with notifcation to either the appender or a tailer than a message has been successfully replicated.

=== Persistence

Chronicle Queue assume disk space is cheap (compared with memory). Enterprise SSD costs have come down. One GB of disk space is worth less than 1 minute of your time on minimum wage (in the UK at time or writing July 2016) Queue makes full use of the disk space you have, and so you are not limited by the main memory of your machine.  If you use spinning HDD, you can store many TB of disk space for little cost.

The only piece of software Chronicle Queue needs to run is the Operating System. It doesn't have a broker, instead it uses your Operating System to do all the work. If you application dies, but the OS keeps running for seconds longer, no data need be lost even without replication. 

As Chronicle Queue stores all saved data in memory mapped files, this has a trivial on heap overhead event if you have over 100 TB of data.

=== Efficiency

We put significant effort into worring about latency you can't see.  Unlike products which focus on support of the web, we care about latency which are a fraction of the time you can see. For web application less than 40 ms is fine for web applications as it's faster than you can see (the frame rate of cinema is 24 Hz or about 40 ms)  However we attempt to be under 40 microsecond 99% to 99.99% of the time.  Using queue without replication we support applications with latencies below 40 microseconds end to end across multiple services.  Often the 99% latency of queue is entirely dependant on the chose of OS and disk subsystem.

=== Compression

Replication for Chronicle Queue support Chronicle Wire Enterprise. This supports a real time compression which calcuates the deltas for individual objects as they are written. This can reduce the size of messages bto 1/10th or better without the need for batching i.e without introducing significnat latency.

Queue also supports LZW, Snappy and GZIP compression however these add non-trival latency.  These are only useful if you have have strick limitations on network bandwidth.

=== Delivery Mode Semantics

Chronicle Queue supports a number symantics.

- every message are replayed on restart
- only new messages are played on restart.
- restart from any known point using the index of the entry.
- replay only message you have missed. This is supported directly using the methodReader/methodWriter builders.

=== Detailed tracing of timings.

Chronicle Queue supprot explicit or implicit nano-second resolution timing for messages as they pass end to end over across you system. We support using nanotime across machine without the need for specialist hardware.

.Enabling high resolution timings
[source, Java]
----
SidedMarketDataListener combiner = out.acquireAppender()
        .methodWriterBuilder(SidedMarketDataListener.class)
        .recordHistory(true)
        .get();
        
combiner.onSidedPrice(new SidedPrice("EURUSD1", 123456789000L, Side.Sell, 1.1172, 2e6));
----

A timestamp is added for each read and write as it passes from service to service.

.Downstream message triggered by the event above
[source, Yaml]
----
--- !!data #binary
history: {
  sources: [
    1,
    0x426700000000 # <4>
  ]
  timings: [
    1394278797664704, # <1>
    1394278822632044, # <2>
    1394278824073475  # <3>
  ]
}
onTopOfBookPrice: {
  symbol: EURUSD1,
  timestamp: 123456789000,
  buyPrice: NaN,
  buyQuantity: 0,
  sellPrice: 1.1172,
  sellQuantity: 2000000.0
}
----
<1> First write
<2> First read
<3> Write of the result of the read.
<4> What triggered this event.

=== Using high resolution timings across machines.

On most systems `System.nanoTime()` is roughly the number of nano-second since the system last reboot (although different JVMs may behave differently)  This is the same across JVM on the same amchine, but wildly different between machines.  The absolute difference machines is meaningless, however the information can be used to detect outliners. i.e. you can't determine what the best latency is, but you can determine how far off the best latencies you are.  This is useful if you are focussing on the 99%ile latencies for example.  We have a class called `RunningMinimum` to obtain timings from different machines while compensating for a drift in the nanoTime between machines. The more often you take measurements the more accurate this running minimum is.

=== Compacting logs

Chronicle Queue manages storage by cycle. You can add a `StoreFileListener` which will notify you when a file is added and when it is no longer retained.  You can move, compress or delete all the message for a day at once.

== Chronicle Queue vs Kafka

Chronicle Queue is designed to support over an order of magnitude the throughput with an order of magnitude lower latency of Kafka.  While Karfa is faster than many of the alternatives it doesn't support both throughputs over million events per second and low latency e.g. 1 - 20 micro-seconds at the same time.

Chronicle Queue attempts to handle more volume from a single thread, to a single partition and thus avoid the need for the complexity and downsides of having partitions.  Note: Chronicle Engine supports partitioning of queues across machines, though not the partitioning of a queue.

Unlike Karfa which uses a broker which uses the operating system's file system and cache.  Chronicle Queue relies entirely on the file system and cache.

=== Similar product guides

http://kafka.apache.org/documentation.html[Kafka Documentation]

